{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2VisualVec for Sentence Representation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This note answers the following two questions:\n",
    "1. How to load a trained Word2VisualVec model?\n",
    "2. How to predict visual features from a new sentence?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the following script to download and extract a Word2VisalVec model trained on flickr30k.\n",
    "Notice that please refer to [here](https://github.com/danieljf24/w2vv#required-data) to download the dataset \n",
    "\n",
    "\n",
    "```shell\n",
    "ROOTPATH=$HOME/trained_w2vv_model\n",
    "mkdir -p $ROOTPATH && cd $ROOTPATH\n",
    "\n",
    "# download and extract the pre-trained model\n",
    "wget http://lixirong.net/data/w2vv-tmm2018/flickr30k_trained_model.tar.gz\n",
    "tar zxf flickr30k_trained_model.tar.gz\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import keras\n",
    "from basic.common import readPkl\n",
    "from w2vv_pred import W2VV_MS_pred, pred_mutual_error_ms\n",
    "from util.text import encode_text\n",
    "from util.text2vec import get_text_encoder\n",
    "from util.util import readImgSents \n",
    "from simpleknn.bigfile import BigFile\n",
    "from util.losser import get_losser\n",
    "from util.evaluation import i2t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load a trained Word2Visual model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/oleh/.local/lib/python2.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling __init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "12/11/2019 22:47:22 INFO [w2vv_pred.pyc.W2VV_MS_pred] loaded a trained Word2VisualVec model successfully\n"
     ]
    }
   ],
   "source": [
    "model_path = os.path.join(os.environ['HOME'],'trained_w2vv_model/flickr30k_trained_model')\n",
    "abs_model_path = os.path.join(model_path, 'model.json')\n",
    "weight_path = os.path.join(model_path, 'best_model.h5')\n",
    "predictor = W2VV_MS_pred(abs_model_path, weight_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Precision of prediction on test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/11/2019 22:47:22 INFO [util/text2vec.pyc.Index2Vec] initializing ...\n",
      "12/11/2019 22:47:22 INFO [util/text2vec.pyc.BoW2VecFilterStop] initializing ...\n",
      "12/11/2019 22:47:22 INFO [util/text2vec.pyc.BoW2VecFilterStop] 7253 words\n",
      "12/11/2019 22:47:22 INFO [util/text2vec.pyc.AveWord2VecFilterStop] initializing ...\n",
      "[BigFile] 1743364x500 instances loaded from /home/oleh/VisualSearch/word2vec/flickr/vec500flickr30m\n"
     ]
    }
   ],
   "source": [
    "# setup multi-scale sentence vectorization\n",
    "trainCollection='flickr30kenctrain'\n",
    "opt = readPkl(os.path.join(model_path, 'option.pkl'))\n",
    "rootpath=os.path.join(os.environ['HOME'],'VisualSearch')\n",
    "rnn_style, bow_style, w2v_style = opt.text_style.strip().split('@')\n",
    "text_data_path = os.path.join(rootpath, trainCollection, \"TextData\", \"vocabulary\", \"bow\", opt.rnn_vocab)\n",
    "bow_data_path = os.path.join(rootpath, trainCollection, \"TextData\", \"vocabulary\", bow_style, opt.bow_vocab)\n",
    "w2v_data_path = os.path.join(rootpath, \"word2vec\", opt.corpus,  opt.word2vec)\n",
    "\n",
    "text2vec = get_text_encoder(rnn_style)(text_data_path)\n",
    "bow2vec = get_text_encoder(bow_style)(bow_data_path)\n",
    "w2v2vec = get_text_encoder(w2v_style)(w2v_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BigFile] 31783x2048 instances loaded from /home/oleh/VisualSearch/flickr30kenctest/FeatureData/pyresnet152-pool5os\n",
      "embedding all sentences ...\n",
      "WARNING:tensorflow:From /home/oleh/.local/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "embedding all images ...\n",
      "matching image and text ...\n",
      "(5000, 1000)\n",
      "Image to text: 34.0, 57.3, 66.8, 4.0, 26.7\n"
     ]
    }
   ],
   "source": [
    "testCollection='flickr30kenctest'\n",
    "\n",
    "# img2vec\n",
    "img_feats_path = os.path.join(rootpath, testCollection, 'FeatureData', opt.img_feature)\n",
    "img_feats = BigFile(img_feats_path)\n",
    "\n",
    "# similarity function\n",
    "losser = get_losser(opt.simi_fun)()\n",
    "\n",
    "test_sent_file = os.path.join(rootpath, testCollection, 'TextData','%s.caption.txt' % testCollection)\n",
    "img_list, sents_id, sents = readImgSents(test_sent_file)\n",
    "all_errors = pred_mutual_error_ms(img_list, sents, predictor, text2vec, bow2vec, w2v2vec, img_feats, losser, opt=opt)\n",
    "\n",
    "\n",
    "# compute performance\n",
    "(r1i, r5i, r10i, medri, meanri) = i2t(all_errors, n_caption=opt.n_caption)\n",
    "print \"Image to text: %.1f, %.1f, %.1f, %.1f, %.1f\" % (r1i, r5i, r10i, medri, meanri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Predict visual features of a novel sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048\n",
      "[0.22264993 0.2669875  0.5451147  ... 0.9105733  0.87271416 0.5411026 ]\n"
     ]
    }
   ],
   "source": [
    "sent='a dog is playing with a cat'\n",
    "rnn_vec, bow_w2v_vec = encode_text(opt,text2vec,bow2vec,w2v2vec,sent)\n",
    "predicted_text_feat = predictor.predict_one(rnn_vec,bow_w2v_vec)\n",
    "print len(predicted_text_feat)\n",
    "print predicted_text_feat"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
