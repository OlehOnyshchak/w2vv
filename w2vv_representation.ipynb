{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2VisualVec for Sentence Representation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This note answers the following two questions:\n",
    "1. How to load a trained Word2VisualVec model?\n",
    "2. How to predict visual features from a new sentence?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the following script to download and extract a Word2VisalVec model trained on flickr30k.\n",
    "Notice that please refer to [here](https://github.com/danieljf24/w2vv#required-data) to download the dataset \n",
    "\n",
    "\n",
    "```shell\n",
    "ROOTPATH=$HOME/trained_w2vv_model\n",
    "mkdir -p $ROOTPATH && cd $ROOTPATH\n",
    "\n",
    "# download and extract the pre-trained model\n",
    "wget http://lixirong.net/data/w2vv-tmm2018/flickr30k_trained_model.tar.gz\n",
    "tar zxf flickr30k_trained_model.tar.gz\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import keras\n",
    "from basic.common import readPkl\n",
    "from w2vv_pred import W2VV_MS_pred, pred_mutual_error_ms\n",
    "from util.text import encode_text\n",
    "from util.text2vec import get_text_encoder\n",
    "from util.util import readImgSents \n",
    "from simpleknn.bigfile import BigFile\n",
    "from util.losser import get_losser\n",
    "from util.evaluation import i2t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_flickr = False\n",
    "\n",
    "model_name = \"flickr30k_trained_model\" if use_flickr else \"1000chars_description_trained_model\"\n",
    "trainCollection = \"flickr30kenctrain\" if use_flickr else 'data_w2vvtrain'\n",
    "testCollection='data_w2vvtest'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load a trained Word2Visual model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling __init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "08/12/2019 13:28:06 INFO [w2vv_pred.pyc.W2VV_MS_pred] loaded a trained Word2VisualVec model successfully\n"
     ]
    }
   ],
   "source": [
    "model_path = os.path.join(os.environ['HOME'],'trained_w2vv_model/' + model_name)\n",
    "abs_model_path = os.path.join(model_path, 'model.json')\n",
    "weight_path = os.path.join(model_path, 'best_model.h5')\n",
    "predictor = W2VV_MS_pred(abs_model_path, weight_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Precision of prediction on test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08/12/2019 13:28:06 INFO [util/text2vec.pyc.Index2Vec] initializing ...\n",
      "08/12/2019 13:28:06 INFO [util/text2vec.pyc.BoW2VecFilterStop] initializing ...\n",
      "08/12/2019 13:28:06 INFO [util/text2vec.pyc.BoW2VecFilterStop] 50105 words\n",
      "08/12/2019 13:28:06 INFO [util/text2vec.pyc.AveWord2VecFilterStop] initializing ...\n",
      "[BigFile] 1743364x500 instances loaded from /home/oleh/VisualSearch/word2vec/flickr/vec500flickr30m\n"
     ]
    }
   ],
   "source": [
    "# setup multi-scale sentence vectorization\n",
    "opt = readPkl(os.path.join(model_path, 'option.pkl'))\n",
    "# opt.n_caption = 2\n",
    "\n",
    "rootpath=os.path.join(os.environ['HOME'],'VisualSearch')\n",
    "rnn_style, bow_style, w2v_style = opt.text_style.strip().split('@')\n",
    "text_data_path = os.path.join(rootpath, trainCollection, \"TextData\", \"vocabulary\", \"bow\", opt.rnn_vocab)\n",
    "bow_data_path = os.path.join(rootpath, trainCollection, \"TextData\", \"vocabulary\", bow_style, opt.bow_vocab)\n",
    "w2v_data_path = os.path.join(rootpath, \"word2vec\", opt.corpus,  opt.word2vec)\n",
    "\n",
    "text2vec = get_text_encoder(rnn_style)(text_data_path)\n",
    "bow2vec = get_text_encoder(bow_style)(bow_data_path)\n",
    "w2v2vec = get_text_encoder(w2v_style)(w2v_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# similarity function\n",
    "losser = get_losser(opt.simi_fun)()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # img2vec\n",
    "# img_feats_path = os.path.join(rootpath, testCollection, 'FeatureData', opt.img_feature)\n",
    "# img_feats = BigFile(img_feats_path)\n",
    "\n",
    "# test_sent_file = os.path.join(rootpath, testCollection, 'TextData','%s.caption.txt' % testCollection)\n",
    "# img_list, sents_id, sents = readImgSents(test_sent_file)\n",
    "# all_errors = pred_mutual_error_ms(img_list, sents, predictor, text2vec, bow2vec, w2v2vec, img_feats, losser, opt=opt)\n",
    "\n",
    "\n",
    "# # compute performance\n",
    "# (r1i, r5i, r10i, medri, meanri) = i2t(all_errors, n_caption=opt.n_caption)\n",
    "# print \"Image to text: %.1f, %.1f, %.1f, %.1f, %.1f\" % (r1i, r5i, r10i, medri, meanri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image to text(flickr run) : 45.6, 72.1, 81.5, 2.0, 13.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image to text(up to 1000 words, vocab from flickr): 1.2, 3.3, 6.4, 115.0, 122.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image to text(entire article, flickr vocab): 0.4, 2.1, 3.7, 362.0, 405.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Specific Output Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import string\n",
    "import json\n",
    "import shutil\n",
    "\n",
    "import os\n",
    "from os import listdir, mkdir\n",
    "from os.path import isfile, isdir, join, exists, abspath\n",
    "from keras.preprocessing import image\n",
    "import regex as re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _remove_punctuation(text):\n",
    "    return re.sub(ur\"\\p{P}+\", \"\", text)\n",
    "\n",
    "def _getJSON(path):\n",
    "    with open(path) as json_file:\n",
    "        return json.loads(json.load(json_file))\n",
    "\n",
    "def _getTextFeatures(text_path):\n",
    "    data = _getJSON(text_path)\n",
    "    text = _remove_punctuation(data['text'].replace(\"\\n\", \" \"))\n",
    "    text = text[:1000].rsplit(' ', 1)[0]\n",
    "    # onyshchak: only checking first 1000 characters, will need to extract summary propely\n",
    "    return {\n",
    "        'id': data['id'],\n",
    "        'text': text,\n",
    "        \"title\": data['title']\n",
    "    }\n",
    "\n",
    "def _getImagesMeta(path):\n",
    "    return _getJSON(path)['img_meta']\n",
    "\n",
    "def _getValidImagePaths(article_path):\n",
    "    img_path = join(article_path, 'img/')\n",
    "    return [join(img_path, f) for f in listdir(img_path) if isfile(join(img_path, f)) and f[-4:].lower() == \".jpg\"]\n",
    "\n",
    "def _dump(path, data):\n",
    "    with open(path, 'w', encoding='utf8') as outfile:\n",
    "        json.dump(data, outfile, indent=2, ensure_ascii=False)\n",
    "\n",
    "def GetArticleData(article_path):\n",
    "    article_data = _getTextFeatures(join(article_path, 'text.json'))\n",
    "    article_data[\"img\"] = _getImagesMeta(join(article_path, 'img/', 'meta.json'))\n",
    "    \n",
    "    return article_data\n",
    "\n",
    "def ReadArticles(data_path, offset=0, limit=None):\n",
    "    print(\"Reading in progress...\")\n",
    "    article_paths = [join(data_path, f) for f in listdir(data_path) if isdir(join(data_path, f))]\n",
    "    limit = limit if limit else len(article_paths) - offset\n",
    "    \n",
    "    articles = []\n",
    "    for i in range(offset, offset + limit):\n",
    "        path = article_paths[i]\n",
    "        if (i - offset + 1) % 251 == 0: print(i - offset, \"articles have been read\")\n",
    "        article_data = GetArticleData(path)\n",
    "        articles.append(article_data)\n",
    "        if len(articles) >= limit: break  # useless?\n",
    "        \n",
    "    print(limit, \"articles have been read\")\n",
    "    return articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading in progress...\n",
      "(250, 'articles have been read')\n",
      "(501, 'articles have been read')\n",
      "(752, 'articles have been read')\n",
      "(1003, 'articles have been read')\n",
      "(1254, 'articles have been read')\n",
      "(1505, 'articles have been read')\n",
      "(1756, 'articles have been read')\n",
      "(2007, 'articles have been read')\n",
      "(2258, 'articles have been read')\n",
      "(2509, 'articles have been read')\n",
      "(2760, 'articles have been read')\n",
      "(3011, 'articles have been read')\n",
      "(3262, 'articles have been read')\n",
      "(3513, 'articles have been read')\n",
      "(3764, 'articles have been read')\n",
      "(4015, 'articles have been read')\n",
      "(4266, 'articles have been read')\n",
      "(4517, 'articles have been read')\n",
      "(4768, 'articles have been read')\n",
      "(5019, 'articles have been read')\n",
      "(5270, 'articles have been read')\n",
      "(5521, 'articles have been read')\n",
      "(5638, 'articles have been read')\n",
      "CPU times: user 48.9 s, sys: 5.8 s, total: 54.7 s\n",
      "Wall time: 59.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "articles = ReadArticles('../data/', offset=0, limit=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Well-performing case of 'Maserati MC12' article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = {i[\"filename\"]: i for a in articles for i in a['img']}\n",
    "images = np.array([x for x in images.values() if \"features\" in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_features = np.array([x[\"features\"] for x in images], dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import hashlib\n",
    "from urllib import quote\n",
    "from IPython.display import display, Image\n",
    "\n",
    "random.seed(1234)\n",
    "\n",
    "def get_matched_article_id(img_features, articles):\n",
    "    for tries in range(50):\n",
    "        i = int(random.random() * len(articles))\n",
    "        page = articles[i]\n",
    "        text = page[\"text\"]\n",
    "        print(i, page['title'])\n",
    "        \n",
    "        rnn_vec, bow_w2v_vec = encode_text(opt, text2vec, bow2vec, w2v2vec, text)\n",
    "        predicted_features = predictor.predict_one(rnn_vec, bow_w2v_vec).reshape(1, -1)\n",
    "\n",
    "        similarity = np.array(losser.calculate(predicted_features, img_features)[0])\n",
    "        true_img = [x[\"filename\"] for x in page[\"img\"]]\n",
    "        for x in images[similarity.argsort()[:10]]:\n",
    "            if x[\"filename\"] in true_img:\n",
    "                print(\"FOUND\", x[\"filename\"])\n",
    "                print(x[\"url\"])\n",
    "                return i\n",
    "    return -1\n",
    "\n",
    "def get_url(img_title, size=600):\n",
    "    img_name = img_title.replace(\"\\\"\", \"\")\n",
    "    for forbidden in ':*?/\\\\ ':\n",
    "        img_name = img_name.replace(forbidden, '_')\n",
    "        \n",
    "    img_name = img_name.encode('utf-8')\n",
    "    url_prefix = \"https://upload.wikimedia.org/wikipedia/commons/thumb/\"\n",
    "    md5 = hashlib.md5(img_name).hexdigest()\n",
    "    sep = \"/\"\n",
    "    \n",
    "    img_name = quote(img_name)\n",
    "    url = url_prefix + sep.join((md5[0], md5[:2], img_name)) + sep + str(size) + \"px-\" + img_name\n",
    "    if url[-4:] != \".jpg\" and url[-4:] != \"jpeg\":\n",
    "        url += \".jpg\"\n",
    "        \n",
    "    return url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5448, u'Vision in White')\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "(2484, u'LSWR N15 class')\n",
      "(42, u'Hurricane Fabian')\n",
      "(5136, u'George Moore (novelist)')\n",
      "(5295, u'Asylum confinement of Christopher Smart')\n",
      "(3282, u'Lost Luggage (video game)')\n",
      "(3786, u'St Kilda, Scotland')\n",
      "(473, u'The Blind Leading the Blind')\n",
      "(4321, u'Triturus')\n",
      "(1335, u'George W. Romney')\n",
      "(173, u'The Shape of Things to Come (Lost)')\n",
      "(4447, u'Smooth toadfish')\n",
      "(1951, u'Aaliyah (album)')\n",
      "(3514, u'Tropical Storm Henri (2003)')\n",
      "(3471, u'Subfossil lemur')\n",
      "(837, u'Maserati MC12')\n",
      "('FOUND', u'd3470178117bd4313f031202c61a9ae8.jpg')\n",
      "https://en.wikipedia.org/wiki/File%3AMaserati_MC12_36643138.jpg\n"
     ]
    }
   ],
   "source": [
    "matched_article_id = get_matched_article_id(img_features, articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Maserati MC12 Tipo M144S is a limited production twoseater sports car produced by Italian car maker Maserati to allow a racing variant to compete in the FIA GT Championship The car entered production in 2004 with 25 cars produced A further 25 were produced in 2005 making a total of 50 cars available for customers each of which was presold for €600000 US$670541 With the addition of 12 cars produced for racing only a total of 62 of these cars were ever produced  Maserati designed and built the car on the chassis of the Enzo Ferrari but the final car is much larger and has a lower drag coefficient The MC12 is longer wider and taller and has a sharper nose and smoother curves than the Enzo Ferrari which has faster acceleration better braking performance shorter braking distance and a higher top speed The top speed of the Maserati MC12 is 330 kilometres per hour 205 mph whereas the top speed of the Enzo Ferrari is 350 kilometres per hour 2175 mph  The MC12 was developed to signal\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[10.183257 ,  3.6151009,  6.8254724, ...,  5.8204355,  8.846998 ,\n",
       "         6.8047595]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# page = [x for x in articles if x[\"title\"] == \"Barack Obama\"][0]\n",
    "page = articles[matched_article_id]\n",
    "text = page[\"text\"]\n",
    "# text = page[\"img\"][1][\"description\"]\n",
    "print(text)\n",
    "rnn_vec, bow_w2v_vec = encode_text(opt, text2vec, bow2vec, w2v2vec, text)\n",
    "predicted_features = predictor.predict_one(rnn_vec, bow_w2v_vec).reshape(1, -1)\n",
    "predicted_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.70614822, -0.59112877, -0.75591392, ..., -0.75365775,\n",
       "       -0.6493101 , -0.8246509 ])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity = np.array(losser.calculate(predicted_features, img_features)[0])\n",
    "# res = res + 1\n",
    "similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Double-checking that `similarity` and `img_features` have the same order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.70614822 -0.59112877 -0.75591392]\n",
      "[-0.75365775 -0.6493101  -0.8246509 ]\n"
     ]
    }
   ],
   "source": [
    "print(similarity[:3])\n",
    "print(similarity[-3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.7061482240913182], [-0.5911287668748487], [-0.7559139236459015]]\n",
      "[[-0.7536577499856756], [-0.6493101040659499], [-0.8246509048925484]]\n"
     ]
    }
   ],
   "source": [
    "print(losser.calculate(img_features[:3], predicted_features))\n",
    "print(losser.calculate(img_features[-3:], predicted_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Double-checking that `images` and `img_features` have the same order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_features = lambda img: np.array(img['features']).astype(np.float32)\n",
    "all([(get_features(images[i]) == img_features[i]).all() for i in range(len(images))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 1 double check that we have the same order, because similarities are very big and results bad\n",
    "* 5 then if doesnt work, train on single image per article (the most relevant one)\n",
    "* 4 finish with text2text similarity (the last priority)\n",
    "* 2 identify article with high precision and check images (is it for real?)\n",
    "* 3 check that we have the same precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.8969546457728494, -0.19520208983797338)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(similarity), max(similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'Maserati MC12'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page[u\"title\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Real images on `Maserati MC12` Wikipedia page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/9/99/Chelsea_Auto_Legends_2012_%287948617098%29.jpg/600px-Chelsea_Auto_Legends_2012_%287948617098%29.jpg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/a/a5/Doran_Maserati.jpg/600px-Doran_Maserati.jpg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/5/51/MC12._%285234528513%29.jpg/600px-MC12._%285234528513%29.jpg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/c/cc/MC12_race_car_front.jpg/600px-MC12_race_car_front.jpg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/a/a4/MC12wheel.JPG/600px-MC12wheel.JPG.jpg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/3/3e/Maserati_MC12_%288675041842%29.jpg/600px-Maserati_MC12_%288675041842%29.jpg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/d/d3/Maserati_MC12_36643138.jpg/600px-Maserati_MC12_36643138.jpg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/a/a7/Maseratibirdcage.jpg/600px-Maseratibirdcage.jpg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/e/ea/Vitaphone_MC12_GT1.jpg/600px-Vitaphone_MC12_GT1.jpg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for x in page[\"img\"]:\n",
    "    img_url = get_url(x['title'])\n",
    "    display(Image(url=img_url))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top-10 ranked images predicted by the model for `Maserati MC12` page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.89695465 -0.89627005 -0.89617854 -0.8949657  -0.89255532 -0.89211503\n",
      " -0.89199204 -0.89196118 -0.89149196 -0.89148102]\n"
     ]
    }
   ],
   "source": [
    "print(similarity[similarity.argsort()[:10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/1/18/Kubica_Brazil_2008_pits.jpg/600px-Kubica_Brazil_2008_pits.jpg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/b/b9/Brabham_BT25.jpg/600px-Brabham_BT25.jpg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/1/13/British_India_Line_arriving_in_Carlisle.jpg/600px-British_India_Line_arriving_in_Carlisle.jpg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/d/d3/Maserati_MC12_36643138.jpg/600px-Maserati_MC12_36643138.jpg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/e/ee/US_Army_51026_Edging_past_Kyle_Busch.jpg/600px-US_Army_51026_Edging_past_Kyle_Busch.jpg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/6/62/F-Zero_AX_deluxe_cabinet.jpg/600px-F-Zero_AX_deluxe_cabinet.jpg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/b/bd/Chester_a_arthur_home.JPG/600px-Chester_a_arthur_home.JPG.jpg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/f/f0/NSE_Gala_London_Bridge_1991_07.JPG/600px-NSE_Gala_London_Bridge_1991_07.JPG.jpg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/e/ea/Vitaphone_MC12_GT1.jpg/600px-Vitaphone_MC12_GT1.jpg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/d/d2/Jazz-realcar.jpg/600px-Jazz-realcar.jpg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for x in images[similarity.argsort()[:10]]:\n",
    "    img_url = get_url(x['title'])\n",
    "    display(Image(url=img_url))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: in case of this article, when taking description of its images as an input, performance is poor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Article Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wiki_predict(page, topK=10):\n",
    "    text = page[\"text\"]\n",
    "    rnn_vec, bow_w2v_vec = encode_text(opt, text2vec, bow2vec, w2v2vec, text)\n",
    "    predicted_features = predictor.predict_one(rnn_vec, bow_w2v_vec).reshape(1, -1)\n",
    "\n",
    "    similarity = np.array(losser.calculate(predicted_features, img_features)[0])\n",
    "    true_img_url = [get_url(x[\"title\"]) for x in page[\"img\"]]\n",
    "    pred_img = images[similarity.argsort()[:topK]]\n",
    "    pred_img_url = [get_url(x[\"title\"]) for x in pred_img]\n",
    "    \n",
    "    return true_img_url, pred_img_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/e/ef/CM_Punk_2.jpg/600px-CM_Punk_2.jpg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/1/10/ClintonSenate.jpg/600px-ClintonSenate.jpg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/0/05/McCain25April2007Portsmouth.jpg/600px-McCain25April2007Portsmouth.jpg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/e/ed/National_Prayer_Service_Obama_Inauguration.jpg/600px-National_Prayer_Service_Obama_Inauguration.jpg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/d/de/RIAN_archive_837790_Valentina_Tereshkova_and_Neil_Armstrong.jpg/600px-RIAN_archive_837790_Valentina_Tereshkova_and_Neil_Armstrong.jpg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/d/d7/The-Dream_performing.jpg/600px-The-Dream_performing.jpg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/8/81/Gough_and_Margaret_Whitlam_-_Holt%27s_memorial_service.jpg/600px-Gough_and_Margaret_Whitlam_-_Holt%27s_memorial_service.jpg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/3/3f/G8_leaders_watching_football.jpg/600px-G8_leaders_watching_football.jpg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/1/17/Michael_Buffer_Fight_For_Children_Washington_DC_Nov_2007.JPG/600px-Michael_Buffer_Fight_For_Children_Washington_DC_Nov_2007.JPG.jpg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/6/6d/Ursula_K_Le_Guin.JPG/600px-Ursula_K_Le_Guin.JPG.jpg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "obama_page = [x for x in articles if x[\"title\"] == \"Barack Obama\"][0]\n",
    "true_img_url, pred_img_url = wiki_predict(obama_page)\n",
    "\n",
    "# Barack Obama's images\n",
    "for x in pred_img_url:\n",
    "    display(Image(url=x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO:** Make sure you checking on examples from **test** subset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Predict visual features of a novel sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048\n",
      "[ 6.1648006  5.2095037  8.546985  ...  7.519165  10.404728   7.7131257]\n"
     ]
    }
   ],
   "source": [
    "sent='a dog is playing with a cat'\n",
    "rnn_vec, bow_w2v_vec = encode_text(opt,text2vec,bow2vec,w2v2vec,sent)\n",
    "predicted_text_feat = predictor.predict_one(rnn_vec,bow_w2v_vec)\n",
    "print len(predicted_text_feat)\n",
    "print predicted_text_feat"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
